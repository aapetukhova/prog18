{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request  # импортируем модуль \n",
    "req = urllib.request.Request('https://habrahabr.ru/')\n",
    "with urllib.request.urlopen(req) as response: #opening of a request\n",
    "   html = response.read().decode('utf-8') #файлообразный объект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"ru\" class=\"no-js\">\n",
      "  <head>\n",
      "    <meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\" />\n",
      "<meta content='width=1024' name='viewport'>\n",
      "<title>Лучшие публикации за сутки / \n"
     ]
    }
   ],
   "source": [
    "print(html[:210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"ru\" class=\"no-js\">\n",
      "  <head>\n",
      "    <meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\" />\n",
      "<meta content='width=1024' name='viewport'>\n",
      "<title>Лучшие публикации за сутки / \n"
     ]
    }
   ],
   "source": [
    "url = 'https://habrahabr.ru/'  # адрес страницы, которую мы хотим скачать\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'  # хотим притворяться браузером\n",
    "\n",
    "req = urllib.request.Request(url, headers={'User-Agent':user_agent})  \n",
    "# добавили в запрос информацию о том, что мы браузер Мозилла\n",
    "\n",
    "with urllib.request.urlopen(req) as response:\n",
    "   html = response.read().decode('utf-8')\n",
    "print(html[:210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "['<h2 class=\"post__title\">\\n    <a href=\"https://habr.com/company/crossover/blog/424701/\" class=\"post__title_link\">Невыдуманные IT-истории о самозванцах и почему появились эти непонятные практики на собеседованиях</a>\\n  </h2>', '<h2 class=\"post__title\">\\n    <a href=\"https://habr.com/company/mosigra/blog/424675/\" class=\"post__title_link\">Что происходит в рознице</a>\\n  </h2>', '<h2 class=\"post__title\">\\n    <a href=\"https://habr.com/post/424767/\" class=\"post__title_link\">Делаем из Хабра торт. Снова</a>\\n  </h2>']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regPostTitle = re.compile('<h2 class=\"post__title\">.*?</h2>', flags= re.DOTALL)\n",
    "titles = regPostTitle.findall(html)\n",
    "# язык, кодировка, ссылка\n",
    "print(len(titles))\n",
    "print(titles[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Невыдуманные IT-истории о самозванцах и почему появились эти непонятные практики на собеседованиях\n",
      "Что происходит в рознице\n",
      "Делаем из Хабра торт. Снова\n",
      "Как поступить на PhD программу по машинному обучению\n",
      "Краткая история цифровой клавиатуры\n",
      "Frontend Conf — с заботой о пользователе\n",
      "Комиссия по ценным бумагам и биржам США подала иск в суд против главы Tesla Илона Маска, в том числе из-за мошенничества\n",
      "Все люди не умеют писать код\n",
      "«У нас есть идеи для Maven 4 и даже Maven 5» — интервью с Robert Scholte, ключевым участником проекта Maven\n",
      "42-й протокол жизни, вселенной и всего такого: «напутственная речь»\n",
      "Деньги любят счёт: как машины сортируют купюры\n",
      "Использование Consul для масштабирования stateful-сервисов\n",
      "Топ-10 докладов Mobius 2018 Piter\n",
      "Горячая история техподдержки, или Почему AutoCAD удаляет прокси-объекты?\n",
      "Антенна из пульверизатора: миниатюрность, гибкость и производительность\n",
      "Как расширять Kubernetes\n",
      "Дайджест событий для HR-специалистов в сфере IT на октябрь 2018\n",
      "Почему компилятор превратил мой цикл с условием в бесконечный?\n"
     ]
    }
   ],
   "source": [
    "new_titles = []\n",
    "regTag = re.compile('<.*?>', re.DOTALL)\n",
    "regSpace = re.compile('\\s{2,}', re.DOTALL) #игнорируем переносы строк, удаляет все пробельные символы, если их > 2, \n",
    "for t in titles:\n",
    "    clean_t = regSpace.sub(\"\", t)\n",
    "    clean_t = regTag.sub(\"\", clean_t)\n",
    "    new_titles.append(clean_t)\n",
    "for t in new_titles:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Невыдуманные IT-истории о самозванцах и почему появились эти непонятные практики на собеседованиях\n",
      "Что происходит в рознице\n",
      "Делаем из Хабра торт. Снова\n",
      "Как поступить на PhD программу по машинному обучению\n",
      "Краткая история цифровой клавиатуры\n",
      "Frontend Conf — с заботой о пользователе\n",
      "Комиссия по ценным бумагам и биржам США подала иск в суд против главы Tesla Илона Маска, в том числе из-за мошенничества\n",
      "Все люди не умеют писать код\n",
      "«У нас есть идеи для Maven 4 и даже Maven 5» — интервью с Robert Scholte, ключевым участником проекта Maven\n",
      "42-й протокол жизни, вселенной и всего такого: «напутственная речь»\n",
      "Деньги любят счёт: как машины сортируют купюры\n",
      "Использование Consul для масштабирования stateful-сервисов\n",
      "Топ-10 докладов Mobius 2018 Piter\n",
      "Горячая история техподдержки, или Почему AutoCAD удаляет прокси-объекты?\n",
      "Антенна из пульверизатора: миниатюрность, гибкость и производительность\n",
      "Как расширять Kubernetes\n",
      "Дайджест событий для HR-специалистов в сфере IT на октябрь 2018\n",
      "Почему компилятор превратил мой цикл с условием в бесконечный?\n"
     ]
    }
   ],
   "source": [
    "for t in new_titles:\n",
    "    print(t.replace(\"&nbsp;&rarr;\", \" -> \"))\n",
    "#     non-breaking space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at http://www.til.ai/50\n",
      "Error at http://www.til.ai/51\n",
      "Error at http://www.til.ai/52\n",
      "Error at http://www.til.ai/53\n",
      "Error at http://www.til.ai/54\n",
      "Error at http://www.til.ai/55\n",
      "Error at http://www.til.ai/56\n",
      "Error at http://www.til.ai/57\n",
      "Error at http://www.til.ai/58\n",
      "Error at http://www.til.ai/59\n",
      "Error at http://www.til.ai/60\n",
      "Error at http://www.til.ai/61\n",
      "Error at http://www.til.ai/62\n",
      "Error at http://www.til.ai/63\n",
      "Error at http://www.til.ai/64\n",
      "Error at http://www.til.ai/65\n",
      "Error at http://www.til.ai/66\n",
      "Error at http://www.til.ai/67\n",
      "Error at http://www.til.ai/68\n",
      "Error at http://www.til.ai/69\n",
      "Error at http://www.til.ai/70\n",
      "Error at http://www.til.ai/71\n",
      "Error at http://www.til.ai/72\n",
      "Error at http://www.til.ai/73\n",
      "Error at http://www.til.ai/74\n",
      "Error at http://www.til.ai/75\n",
      "Error at http://www.til.ai/76\n",
      "Error at http://www.til.ai/77\n",
      "Error at http://www.til.ai/78\n",
      "Error at http://www.til.ai/79\n",
      "Error at http://www.til.ai/80\n",
      "Error at http://www.til.ai/81\n",
      "Error at http://www.til.ai/82\n",
      "Error at http://www.til.ai/83\n",
      "Error at http://www.til.ai/84\n",
      "Error at http://www.til.ai/85\n",
      "Error at http://www.til.ai/86\n",
      "Error at http://www.til.ai/87\n",
      "Error at http://www.til.ai/88\n",
      "Error at http://www.til.ai/89\n",
      "Error at http://www.til.ai/90\n",
      "Error at http://www.til.ai/91\n",
      "Error at http://www.til.ai/92\n",
      "Error at http://www.til.ai/93\n",
      "Error at http://www.til.ai/94\n",
      "Error at http://www.til.ai/95\n",
      "Error at http://www.til.ai/96\n",
      "Error at http://www.til.ai/97\n",
      "Error at http://www.til.ai/98\n",
      "Error at http://www.til.ai/99\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "def download_page(pageUrl):\n",
    "    try:\n",
    "        page = urllib.request.urlopen(pageUrl)\n",
    "        text = page.read().decode('ISO-8859-1')\n",
    "    except:\n",
    "        print('Error at', pageUrl)\n",
    "        return\n",
    "    # do something with the downloaded text\n",
    "# в случае любой ошибки - сообщение, а можно указать конкретный тип ошибки\n",
    "commonUrl = 'http://www.til.ai/'\n",
    "for i in range(50, 100):\n",
    "    pageUrl = commonUrl + str(i)\n",
    "    download_page(pageUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are no more articles\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# если мы не знаем количество заголовков - try-accept\n",
    "try:\n",
    "    print(new_title[:25])\n",
    "except:\n",
    "    print('there are no more articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "1 a\n",
      "2 a\n",
      "3 a\n",
      "4 a\n",
      "5 a\n",
      "6 a\n",
      "7 a\n",
      "8 a\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_page(pageUrl):\n",
    "    try:\n",
    "        page = urllib.request.urlopen(pageUrl)\n",
    "        text = page.read().decode('utf-8')\n",
    "        soup = BeautifulSoup(text, 'html.parser')\n",
    "        for article in soup.find_all('div', {'class': 'result_headword'}):\n",
    "            print(article.find('h3').get_text())\n",
    "    except:\n",
    "        print('Error at', pageUrl)\n",
    "        return\n",
    "#     return soup\n",
    "    \n",
    "\n",
    "    \n",
    "commonUrl = 'http://dil.ie/'\n",
    "for i in range(1, 10):\n",
    "    pageUrl = commonUrl + str(i)\n",
    "    download_page(pageUrl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
